Welcome to Lab 1!

In this lab we will be covering the very basics of Tool use

There are 4 Python files in this Lab

The Files are
- frontend_lab1.py : This file contains our Front End Streamlit Logic - we will run this file when we want to access the GUI for the Lab
- logic_lab_1.py : This File contains the logic and structuring of how the LLM model gets called. 
    This file is functional and we will be using it for some initial testing and when we want to adjust some of the LLM Behavior
- tools_lab_1.py : This File contains or Tools. The Tool Definitions, their corresponding logic and code, and how to execute the code. When we add tools, we will add them here!
- misc_functions.py : THis file handles some miscellaneous functions that we don't need to touch during the lab

In Lab 1 we will be covering the following
- Walking through the code of the Bedrock Converse API
- Testing the inputs and outputs
- Running the UI 
- Adding a Tool
- Adjusting the LLM's directions on how and when to use tools


Step 1 - Introduction to the Bedrock Converse API
- Open up logic_lab_1.py and review
- Note how how Converse API is structured, and how it determines the model to use
- Run the File - from the Lab1_Basic_Tool_Use Directory run the command "python ./logic_lab_1"
- Review the results in your terminal

Step 2 - Start the UI
- Before Starting the UI comment out the following line (adding # in front of it) in logic_lab_1.py - test_run(message_1, message_2, message_3, model) - It will be the last line of the code. Save the file after commenting out that line
- In your terminal run the following command to kick off the UI - "streamlit run frontend_lab_1.py --server.port 8080 --server.enableXsrfProtection=False"
- In your cloud 9 environment select the "Preview Running Application Button"
- Try it out! Ask for random numbers, with and without specifying the range. Ask questions about general knowledge. Note the results
- Try to break it! FIRST PERSON TO BREAK IT GETS A PRIZE! - To Qualify the UI must return an error (and the code has to be right!)

Step 3 - Making a new Tool 
- We will create a new tool by adding a tool definition, adding that definition to our tool list, and creating a function that will execute the logic for our tool
- First, stop the UI by pressing control+C in the terminal
- In the file tools_lab_1.py Remove the comment blocks to activate the following:
    - The Tool configuration for "hello_response_tool_def"
    - The line of code that adds the tool definition to the list: "tool_definition.append(hello_response_tool_def)"
    - The Method that implements the tool logic "def hello_response(user_name=None):"
- Save all changes
- Run the UI again with the command - "streamlit run frontend_lab_1.py --server.port 8080 --server.enableXsrfProtection=False"
- Note the differences

Step 4 - Guiding the model on Tool use via the System Prompt
- If we want to tell the model that it can ONLY use tools, and that it should not respond on its own we can direct the model to do so
- Often time a tool's logic will use LLM's, But those downstream models will be significantly more focused on a specific task, use a specific model (like a cusotmized model, r an image to text model), or have specific X-shot exmaples or knowledge bases (Hint for LAB 2!)
- To restrict our current application so that it should ONLY use its tools, lets adjust the system prompt in logic_lab_1.py
- In the converse_with_bedrock method, CHange the existing system prompt, or uncomment the commented out system prompt so that the model will return a specific message if no tools will assist in the task
- Save the changes
- Run the UI again with the command - "streamlit run frontend_lab_1.py --server.port 8080 --server.enableXsrfProtection=False"
- Note the differences 


Congratulations, you have completed Lab 1!
I hope you have a better understanding of Tool Use / Function Calling
Now lets hop into Lab 2 and lets see some more Industry specific tools in Action 